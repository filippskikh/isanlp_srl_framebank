{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lkmfwe/anaconda3/envs/isanlp_srl_framebank/lib/python3.6/site-packages/OpenSSL/crypto.py:8: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography and will be removed in a future release.\n",
      "  from cryptography import utils, x509\n",
      "[nltk_data] Downloading package punkt to /home/lkmfwe/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/lkmfwe/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package perluniprops to\n",
      "[nltk_data]     /home/lkmfwe/nltk_data...\n",
      "[nltk_data]   Package perluniprops is already up-to-date!\n",
      "[nltk_data] Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]     /home/lkmfwe/nltk_data...\n",
      "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import conllu\n",
    "import fire\n",
    "import os\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from isanlp_srl_framebank.pipeline_default import PipelineDefault\n",
    "import re\n",
    "import sys\n",
    "\n",
    "from isanlp.processor_remote import ProcessorRemote\n",
    "from isanlp.processor_syntaxnet_remote import ProcessorSyntaxNetRemote\n",
    "from isanlp import PipelineCommon\n",
    "from isanlp.ru.converter_mystem_to_ud import ConverterMystemToUd\n",
    "from isanlp_srl_framebank.processor_srl_framebank import ProcessorSrlFramebank\n",
    "import json\n",
    "from pprint import pprint as print_\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "WORKDIR = \"../../../workdir2_nocoref\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "random_seed = 41\n",
    "\n",
    "roleset44 = {\n",
    " 'содержание высказывания',\n",
    " 'говорящий',\n",
    " 'субъект социального отношения',\n",
    " 'субъект психологического состояния',\n",
    " 'содержание действия',\n",
    " 'агенс',\n",
    " 'тема',\n",
    " 'конечная точка',\n",
    " 'сфера',\n",
    " 'контрагент',\n",
    " 'субъект перемещения',\n",
    " 'причина',\n",
    " 'субъект поведения',\n",
    " 'ситуация в фокусе',\n",
    " 'исходный посессор',\n",
    " 'субъект физиологической реакции',\n",
    " 'адресат',\n",
    " 'пациенс',\n",
    " 'срок',\n",
    " 'источник звука',\n",
    " 'место',\n",
    " 'признак',\n",
    " 'потенциальная угроза',\n",
    " 'субъект ментального состояния',\n",
    " 'конечный посессор',\n",
    " 'результат',\n",
    " 'стимул',\n",
    " 'субъект восприятия',\n",
    " 'эффектор',\n",
    " 'траектория',\n",
    " 'содержание мысли',\n",
    " 'пациенс перемещения',\n",
    " 'каузатор',\n",
    " 'предмет высказывания',\n",
    " 'начальная точка',\n",
    " 'способ',\n",
    " 'пациенс социального отношения',\n",
    " 'статус',\n",
    " 'предмет мысли',\n",
    " 'цель',\n",
    " 'потенциальный пациенс',\n",
    " 'контрагент социального отношения',\n",
    " 'эталон',\n",
    " 'признак действия'}\n",
    "\n",
    "ARGUMENT_POSTAGS = {\n",
    "        'NOUN',\n",
    "        'PRON',\n",
    "        'ADJ',\n",
    "        'PROPN'\n",
    "    }\n",
    "\n",
    "def get_roles_pred(lemma, role_annot, part_id):\n",
    "    ann_sent = role_annot[part_id]\n",
    "    predicates = {}\n",
    "    arguments = {}\n",
    "    for event in ann_sent:\n",
    "        predicate = {\n",
    "            'lemma': lemma[part_id][event.pred[0]],\n",
    "        }\n",
    "        predicates[event.pred[0]] = predicate\n",
    "        arguments[event.pred[0]] = []\n",
    "        for arg in event.args:\n",
    "            argument = {\n",
    "                'tag': arg.tag,\n",
    "                'lemma': lemma[part_id][arg.begin],\n",
    "                'idx': arg.begin\n",
    "            }\n",
    "            arguments[event.pred[0]].append(argument)\n",
    "\n",
    "    return predicates, arguments\n",
    "\n",
    "\n",
    "def get_example(corpus, ex_number, part_id):\n",
    "    words = []\n",
    "    for obj in corpus[ex_number][1][part_id]:\n",
    "        word = obj['form']\n",
    "        for symbol in ':;,.!?':\n",
    "            word = word.replace(' ' + symbol, symbol)\n",
    "        words.append(word)\n",
    "\n",
    "    if words:\n",
    "        return ' '.join(words)\n",
    "    else:\n",
    "        return '_'\n",
    "\n",
    "\n",
    "def get_roles_true(annot, corpus, ex_number, part_id):\n",
    "    predicates = {}\n",
    "    arguments = {}\n",
    "    postags = [item for sublist in annot['postag'] for item in sublist]\n",
    "    for i, obj in enumerate(corpus[ex_number][1][part_id]):\n",
    "        if 'rank' in obj:\n",
    "            if obj['rank'] == 'Предикат':\n",
    "                predicate = {\n",
    "                    'lemma': obj['lemma']\n",
    "                }\n",
    "                predicates[i] = predicate\n",
    "            else:\n",
    "                if 'lemma' not in obj:\n",
    "                    argument = {\n",
    "                        'lemma': obj['form'],\n",
    "                        'tag': obj['rolepred1'],\n",
    "                        'idx': i\n",
    "                    }\n",
    "                else:\n",
    "                    argument = {\n",
    "                        'lemma': obj['lemma'],\n",
    "                        'tag': obj['rolepred1'],\n",
    "                        'idx': i\n",
    "                    }\n",
    "\n",
    "                argument['postag'] = postags[argument['idx']]\n",
    "                pred_id = obj['fillpred']\n",
    "                if pred_id not in arguments.keys():\n",
    "                    arguments[pred_id] = []\n",
    "                arguments[pred_id].append(argument)\n",
    "\n",
    "    return predicates, arguments\n",
    "\n",
    "def random_texts(corpus, ppl, n_samples=100):\n",
    "    if len(corpus) > n_samples:\n",
    "        np.random.seed(random_seed)\n",
    "        samples_idxs = np.random.choice(len(corpus), size=n_samples)\n",
    "    else:\n",
    "        samples_idxs = [_ for _ in range(len(corpus))]\n",
    "\n",
    "    texts = [get_example(corpus, ex_num, 0) for ex_num in samples_idxs]\n",
    "    return texts\n",
    "\n",
    "def random_predictions(corpus, ppl, n_samples=100):\n",
    "    if len(corpus) > n_samples:\n",
    "        np.random.seed(random_seed)\n",
    "        samples_idxs = np.random.choice(len(corpus), size=n_samples)\n",
    "    else:\n",
    "        samples_idxs = [_ for _ in range(len(corpus))]\n",
    "\n",
    "    texts = [get_example(corpus, ex_num, 0) for ex_num in samples_idxs]\n",
    "\n",
    "    annotations = [ppl(text) for text in tqdm(texts, desc='Analyzing texts')]\n",
    "    pred_roles = [get_roles_pred(res['lemma'], res['srl'], 0) for res in annotations]\n",
    "\n",
    "    true_roles = [get_roles_true(annotations[i], corpus, ex_num, 0) for i, ex_num in enumerate(samples_idxs)]\n",
    "\n",
    "\n",
    "    repl_roles = {\n",
    "        'агенс - субъект восприятия' : 'субъект восприятия',\n",
    "        'агенс - субъект ментального состояния' : 'субъект ментального состояния',\n",
    "        'результат / цель' : 'результат',\n",
    "        'место - пациенс' : 'место',\n",
    "        'говорящий - субъект психологического состояния' : 'субъект психологического состояния'\n",
    "    }\n",
    "\n",
    "    for role, val in repl_roles.items():\n",
    "        for pair in true_roles:\n",
    "            for _, args in pair[1].items():\n",
    "                for arg in args:\n",
    "                    arg['tag'] = arg['tag'].replace(role, val)\n",
    "\n",
    "    return true_roles, pred_roles, texts\n",
    "\n",
    "\n",
    "def compute_metrics(y_pred, y_true, report_to=sys.stdout, roleset=roleset44, idxmatching=False):\n",
    "    true_positive = 0\n",
    "    condition_positive = 0\n",
    "    predicted_condition_positive = 0\n",
    "    error_examples = []\n",
    "\n",
    "    print_func = lambda x: print(x, file=report_to)\n",
    "\n",
    "    for i, (true_predicates, true_arguments) in enumerate(y_true):\n",
    "        print_func(f\"Inspecting example {i}\")\n",
    "        print_func(f\"Expecting true predicates {true_predicates}\")\n",
    "        print_func(f\"Expecting true arguments  {true_arguments}\")\n",
    "\n",
    "        pred_predicates, pred_arguments = y_pred[i]\n",
    "\n",
    "        print_func(f\"Got predicted predicates  {pred_predicates}\")\n",
    "        print_func(f\"Got predicted arguments   {pred_arguments}\")\n",
    "\n",
    "        print_func(\"-\"*60)\n",
    "\n",
    "        for true_pred_idx, true_predicate in true_predicates.items():\n",
    "            if true_pred_idx in pred_predicates:\n",
    "                print_func(f\"Matched predicate {true_pred_idx} = {true_predicate}\")\n",
    "\n",
    "                true = true_arguments[true_pred_idx]\n",
    "                pred_arguments_i = pred_arguments[true_pred_idx]\n",
    "\n",
    "                true_arguments_i = []\n",
    "\n",
    "                for idx, true_argument in enumerate(true):\n",
    "                    if true_argument['tag'] in roleset and true_argument['postag'] in ARGUMENT_POSTAGS:\n",
    "                        true_arguments_i.append(true[idx])\n",
    "\n",
    "                if true_arguments_i:\n",
    "                    print_func(f\"Expecting arguments  {true_arguments_i}\")\n",
    "                    print_func(f\"Got predicted        {pred_arguments_i}\")\n",
    "                    print_func(f\"Predicted Condition Positive = {len(pred_arguments_i)}\")\n",
    "                    print_func(f\"Condition Positive           = {len(true_arguments_i)}\")\n",
    "                    condition_positive += len(true_arguments_i)\n",
    "                    condition_positive_i = len(true_arguments_i)\n",
    "                    predicted_condition_positive += len(pred_arguments_i)\n",
    "\n",
    "                    true_positive_i = 0\n",
    "\n",
    "                    error_report = {\n",
    "                        'example_idx' : i,\n",
    "                        'predicate': true_predicate,\n",
    "                        'true_arguments' : true_arguments_i,\n",
    "                        'predicted_arguments': pred_arguments_i\n",
    "                    }\n",
    "\n",
    "                    for j, obj in enumerate(true_arguments_i):\n",
    "                        true_tag = obj['tag']\n",
    "                        true_lemma = obj['lemma']\n",
    "                        true_idx = obj['idx']\n",
    "                        for obj_pred in pred_arguments_i:\n",
    "                            if idxmatching:\n",
    "                                if obj_pred['idx'] == true_idx:\n",
    "                                    true_positive_i += 1\n",
    "                            else:\n",
    "                                if obj_pred['idx'] == true_idx and obj_pred['tag'] == true_tag:\n",
    "                                    true_positive_i += 1\n",
    "\n",
    "                    print_func(f\"True Positive = {true_positive_i}\")\n",
    "                    if true_positive_i != condition_positive_i:\n",
    "                        error_examples.append(error_report)\n",
    "\n",
    "                    true_positive += true_positive_i\n",
    "\n",
    "        print_func(\"=\"*60)\n",
    "\n",
    "    recall = true_positive/condition_positive\n",
    "    precision = true_positive/predicted_condition_positive\n",
    "\n",
    "    return {\n",
    "        'recall': recall,\n",
    "        'precision': precision,\n",
    "        'f1': 2 * ((precision*recall)/(precision+recall)),\n",
    "        'errors': error_examples\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/lkmfwe/anaconda3/envs/isanlp_srl_framebank/lib/python3.6/site-packages/deeppavlov/models/embedders/elmo_embedder.py:186: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lkmfwe/anaconda3/envs/isanlp_srl_framebank/lib/python3.6/site-packages/deeppavlov/models/embedders/elmo_embedder.py:188: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lkmfwe/anaconda3/envs/isanlp_srl_framebank/lib/python3.6/site-packages/deeppavlov/models/embedders/elmo_embedder.py:190: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "WARNING:tensorflow:From /home/lkmfwe/anaconda3/envs/isanlp_srl_framebank/lib/python3.6/site-packages/deeppavlov/models/embedders/elmo_embedder.py:198: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "srl_proc = ProcessorSrlFramebank(WORKDIR, 'elmo')\n",
    "\n",
    "def srl_ppl(tokens, postag, morph, lemma, syntax_dep_tree):\n",
    "    srl_annot = srl_proc(tokens, postag, morph, lemma, syntax_dep_tree)\n",
    "    return srl_annot\n",
    "\n",
    "ppl = PipelineCommon([(ProcessorRemote('localhost', 3333, 'default'),\n",
    "                           ['text'],\n",
    "                           {'tokens': 'tokens',\n",
    "                            'sentences': 'sentences',\n",
    "                            'postag': 'mystem_postag',\n",
    "                            'lemma': 'lemma'}),\n",
    "                          (ProcessorSyntaxNetRemote('localhost', 3334),\n",
    "                           ['tokens', 'sentences'],\n",
    "                           {'syntax_dep_tree': 'syntax_dep_tree'}),\n",
    "                          (ConverterMystemToUd(),\n",
    "                           ['mystem_postag'],\n",
    "                           {'morph': 'morph',\n",
    "                            'postag': 'postag'}),\n",
    "                          (srl_ppl,\n",
    "                           ['tokens', 'postag', 'morph', 'lemma', 'syntax_dep_tree'],\n",
    "                           {'srl': 'srl'})])\n",
    "def sprint_roles(lemma, role_annot):\n",
    "    s = \"\"\n",
    "    for sent_num, ann_sent in enumerate(role_annot):\n",
    "        for event in ann_sent:\n",
    "            s += '=====Pred: {}\\n'.format(lemma[sent_num][event.pred[0]])\n",
    "            for arg in event.args:\n",
    "                s += 'Arg({}): {}\\n'.format(arg.tag, lemma[sent_num][arg.begin])\n",
    "    return s\n",
    "\n",
    "def srl(text):\n",
    "    annots = ppl(text)\n",
    "\n",
    "    return annots, sprint_roles(annots['lemma'], annots['srl'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'srl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-1-889c3f1c8940>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mannots\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mprettyprint\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msrl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Кошка грелась на солнце\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprettyprint\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m \u001B[0mx\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mannots\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'srl'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'srl' is not defined"
     ]
    }
   ],
   "source": [
    "annots, prettyprint = srl(\"Кошка грелась на солнце\")\n",
    "\n",
    "print(prettyprint)\n",
    "print([ x for x in annots['srl']])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "1000"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_path = f'{WORKDIR}/test_data.json'\n",
    "with open(corpus_path, 'r', encoding='utf-8') as f:\n",
    "    corpus = json.load(f)\n",
    "len(corpus)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предикат: посадить\n",
      "3 (это) эталон\n",
      "4 (ты) агенс\n",
      "Предикат: прерывать\n",
      "13 (он) пациенс\n",
      "15 (катя) агенс\n"
     ]
    }
   ],
   "source": [
    "res = ppl('- И за это тебя посадят, -- как бы сообразив, прервала его тётя Катя.')\n",
    "\n",
    "for event in res['srl'][0]:\n",
    "    print(\"Предикат:\", res['lemma'][0][event.pred[0]])\n",
    "    for i in range(len(event.args)):\n",
    "        print(event.args[i].begin, f\"({res['lemma'][0][event.args[i].begin]})\", event.args[i].tag)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lkmfwe/anaconda3/envs/isanlp_srl_framebank/lib/python3.6/site-packages/ipykernel_launcher.py:143: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "text/plain": "Analyzing texts:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aadca231a14f478ca04aaa85ad7518a0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "true_roles, pred_roles, tmp_texts = random_predictions(corpus, ppl, n_samples=len(corpus))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': 0.7409470752089136,\n",
      " 'precision': 0.751412429378531,\n",
      " 'recall': 0.7307692307692307}\n"
     ]
    }
   ],
   "source": [
    "log_path = 'log_idx.txt'\n",
    "results = compute_metrics(y_pred=pred_roles, y_true=true_roles,\n",
    "                          report_to=open(log_path, 'w', encoding='utf-8'),\n",
    "                          idxmatching=True)\n",
    "\n",
    "copyres = dict(results)\n",
    "del copyres['errors']\n",
    "print_(copyres)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}